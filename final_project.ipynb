{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0078783c",
      "metadata": {
        "id": "0078783c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "29024d06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "29024d06",
        "outputId": "955f2c70-3b9c-41c8-f722-42c553449acd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-58b05e2e-b2da-45a7-9c2d-b0e114ddda18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>GroundTruth</th>\n",
              "      <th>Ratings</th>\n",
              "      <th>Review Date</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I visit this place with my friends. It was ver...</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>1-Mar-20</td>\n",
              "      <td>The Best Italian Food in Larissa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It deserves every star given in Trip Advisor. ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>9-Jan-20</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great good and value for money. A must visit i...</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>20-Dec-19</td>\n",
              "      <td>Great good!</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We went with friends. We took seats in the gar...</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>7-Jun-19</td>\n",
              "      <td>Delicious food, excellent service</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beautiful and cosy place ! Delicious and big p...</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>6-Mar-19</td>\n",
              "      <td>Excellent !</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58b05e2e-b2da-45a7-9c2d-b0e114ddda18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58b05e2e-b2da-45a7-9c2d-b0e114ddda18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58b05e2e-b2da-45a7-9c2d-b0e114ddda18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         Description  ... Site\n",
              "0  I visit this place with my friends. It was ver...  ...  NaN\n",
              "1  It deserves every star given in Trip Advisor. ...  ...  NaN\n",
              "2  Great good and value for money. A must visit i...  ...  NaN\n",
              "3  We went with friends. We took seats in the gar...  ...  NaN\n",
              "4  Beautiful and cosy place ! Delicious and big p...  ...  NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/e_food_restaurants_reviews_thessaly.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22283d10",
      "metadata": {
        "id": "22283d10"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"Site\", \"Review Date\", \"Review Title\", \"Ratings\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ff97d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff97d37",
        "outputId": "2d20d34a-df56-4a9a-ff0f-19675d34cd25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Description GroundTruth\n",
            "0     I visit this place with my friends. It was ver...    positive\n",
            "1     It deserves every star given in Trip Advisor. ...    positive\n",
            "2     Great good and value for money. A must visit i...    positive\n",
            "3     We went with friends. We took seats in the gar...    positive\n",
            "4     Beautiful and cosy place ! Delicious and big p...    positive\n",
            "...                                                 ...         ...\n",
            "1035  Staff was very polite, the music and the ambie...    positive\n",
            "1036  Nice place very good food, fast service good p...    positive\n",
            "1037  We were about 20 people and they didn't have a...    positive\n",
            "1038  Everything said in the title :)\\nWe came to Tr...    positive\n",
            "1039  Went here for dinner. the server was excellent...    positive\n",
            "\n",
            "[1040 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5d9a8d01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "5d9a8d01",
        "outputId": "ca5dbd94-710b-4093-c986-591457957851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-75749bad-c7ee-4c62-b4e1-e03c02f2a9bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>GroundTruth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1040</td>\n",
              "      <td>1040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>481</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Great place to visit and taste high gastronomy...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>8</td>\n",
              "      <td>950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75749bad-c7ee-4c62-b4e1-e03c02f2a9bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75749bad-c7ee-4c62-b4e1-e03c02f2a9bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75749bad-c7ee-4c62-b4e1-e03c02f2a9bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              Description GroundTruth\n",
              "count                                                1040        1040\n",
              "unique                                                481           2\n",
              "top     Great place to visit and taste high gastronomy...    positive\n",
              "freq                                                    8         950"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "32d0f55d",
      "metadata": {
        "id": "32d0f55d"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={\"GroundTruth\": \"Rating\", \"Description\" : \"Review\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1a40843",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1a40843",
        "outputId": "e81af8ff-8562-42a8-bd27-ae24d038372f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    950\n",
              "negative     90\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['Rating'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "86890ee4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86890ee4",
        "outputId": "cb5cc3da-4004-44b1-aa78-e14869f57929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(696,) (696,)\n",
            "(344,) (344,)\n"
          ]
        }
      ],
      "source": [
        "train_reviews, test_reviews, train_sentiments, test_sentiments = train_test_split(df.Review, df.Rating, test_size=0.33, random_state=42)\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "N_Z3kvLVokQn",
        "outputId": "dbc5a21a-5211-44e8-e510-bff4b8005e4b"
      },
      "id": "N_Z3kvLVokQn",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 26.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Installing collected packages: regex, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.7 regex-2022.1.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "regex"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "efa12791",
      "metadata": {
        "id": "efa12791"
      },
      "outputs": [],
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9d3783b5",
      "metadata": {
        "id": "9d3783b5"
      },
      "outputs": [],
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['Review']=df['Review'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ff6a7330",
      "metadata": {
        "id": "ff6a7330"
      },
      "outputs": [],
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['Review']=df['Review'].apply(remove_special_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6d663489",
      "metadata": {
        "id": "6d663489"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['Review']=df['Review'].apply(simple_stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d445d6f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d445d6f8",
        "outputId": "5246e799-3757-48a0-8b84-7fb992c00368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"she's\", 'your', 'if', 'their', 'that', 'them', \"it's\", 'wouldn', 'once', 'the', \"you've\", 'most', 'she', 'isn', 'an', 'aren', 'as', 'by', \"hasn't\", 'theirs', \"shan't\", 'his', \"didn't\", 'itself', \"should've\", \"won't\", 'few', 'myself', 'they', 'into', \"don't\", 'what', 'why', 'about', 'where', 'her', 'under', \"couldn't\", 'has', \"aren't\", 'for', 'some', 'all', 'over', 'can', 'nor', 't', 'because', 'very', 'you', 'whom', 'through', 'm', 'after', 'was', \"shouldn't\", \"that'll\", 'were', 'any', 'yours', \"you'll\", 'which', 'only', 'been', 'doesn', 'yourselves', 'from', 'had', 'my', 'each', 'being', 'just', \"wouldn't\", 'against', 'hers', 'do', \"needn't\", 'didn', 's', 'will', 'between', 'doing', 'me', 'our', 'than', 'mightn', 'but', 'did', \"you'd\", 've', 'both', 'll', 'its', 'to', 'now', 'hadn', 'd', \"mightn't\", 'more', \"wasn't\", 'have', 'down', 'this', 'not', 'hasn', 'herself', 'wasn', 'yourself', 'of', 'it', 'up', 'be', 'couldn', 'him', 'so', 'weren', 'own', 'there', 'and', 'with', 'don', 'ourselves', 'those', 'am', 'does', 'in', 'when', \"haven't\", \"isn't\", 'same', \"mustn't\", 'shan', 'again', 'then', 'further', \"weren't\", 'before', 'at', 'while', 'haven', 'ma', 'too', 'ain', 'who', 'themselves', 'are', 'out', 'off', 'here', \"hadn't\", \"doesn't\", \"you're\", 'needn', 'is', 'himself', 'or', 'during', 'won', 'a', 'on', 'ours', 'how', 'no', 'these', 'mustn', 'he', 'having', 'above', 'o', 'shouldn', 'i', 'other', 'until', 'such', 're', 'we', 'should', 'y', 'below'}\n"
          ]
        }
      ],
      "source": [
        "#set stopwords to english\n",
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "df['Review']=df['Review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ddcc0f6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ddcc0f6a",
        "outputId": "6a0c191d-b1da-4115-a0fd-5865983223a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I visit this place with my friends. It was very nice restaurant with  special italian food and the service exellent.'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#normalized train reviews\n",
        "norm_train_reviews=train_reviews\n",
        "norm_train_reviews[0]\n",
        "#convert dataframe to string\n",
        "#norm_train_string=norm_train_reviews.to_string()\n",
        "#Spelling correction using Textblob\n",
        "#norm_train_spelling=TextBlob(norm_train_string)\n",
        "#norm_train_spelling.correct()\n",
        "#Tokenization using Textblob\n",
        "#norm_train_words=norm_train_spelling.words\n",
        "#norm_train_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0a612c16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0a612c16",
        "outputId": "22c38e3a-b7bf-4f5c-c191-0f107fc8618e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I come there with a friend for lunch, I took a dish of carbonara, while he took a \"Fiorentina\" meat. Both dishes were very tasty, and also the staff was very kind. I will return there!'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Normalized test reviews\n",
        "norm_test_reviews=test_reviews\n",
        "norm_test_reviews[31]\n",
        "##convert dataframe to string\n",
        "#norm_test_string=norm_test_reviews.to_string()\n",
        "#spelling correction using Textblob\n",
        "#norm_test_spelling=TextBlob(norm_test_string)\n",
        "#print(norm_test_spelling.correct())\n",
        "#Tokenization using Textblob\n",
        "#norm_test_words=norm_test_spelling.words\n",
        "#norm_test_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb53ec3d",
      "metadata": {
        "id": "bb53ec3d"
      },
      "source": [
        "# a. VANDER knowledge based unsupervised model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4aeb462b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aeb462b",
        "outputId": "baecaf2f-b21d-4952-dc50-00aba5b9b14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "#reviews_df[\"sentiments\"] = reviews_df[\"review\"].apply(lambda x: sid.polarity_scores(x))\n",
        "#reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8737f28d",
      "metadata": {
        "id": "8737f28d"
      },
      "outputs": [],
      "source": [
        "df[\"sentiments\"] = df[\"Review\"].apply(lambda x: sid.polarity_scores(x))\n",
        "df = pd.concat([df.drop(['sentiments'], axis=1), df['sentiments'].apply(pd.Series)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b2a7b5e9",
      "metadata": {
        "id": "b2a7b5e9"
      },
      "outputs": [],
      "source": [
        "# add number of characters column\n",
        "df[\"nb_chars\"] = df[\"Review\"].apply(lambda x: len(x))\n",
        "\n",
        "\n",
        "# add number of words column\n",
        "df[\"nb_words\"] = df[\"Review\"].apply(lambda x: len(x.split(\" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178d80fe",
      "metadata": {
        "id": "178d80fe"
      },
      "source": [
        "# b. Apply TFIDF (term frequency, inverse document frequency) vectorization to reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ca251446",
      "metadata": {
        "id": "ca251446"
      },
      "outputs": [],
      "source": [
        "# add tf-idfs columns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df = 10)\n",
        "tfidf_result = tfidf.fit_transform(df[\"Review\"]).toarray()\n",
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
        "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
        "tfidf_df.index = df.index\n",
        "df = pd.concat([df, tfidf_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6a70e17f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "6a70e17f",
        "outputId": "2dd220f3-0f8b-40c8-92f8-35739bba5b7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9c8f31f-a46b-4370-a1c8-21f9c12204e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>nb_chars</th>\n",
              "      <th>nb_words</th>\n",
              "      <th>word_10</th>\n",
              "      <th>word_20</th>\n",
              "      <th>word_abov</th>\n",
              "      <th>word_absolut</th>\n",
              "      <th>word_advisor</th>\n",
              "      <th>word_afford</th>\n",
              "      <th>word_ago</th>\n",
              "      <th>word_akamatra</th>\n",
              "      <th>word_almost</th>\n",
              "      <th>word_along</th>\n",
              "      <th>word_also</th>\n",
              "      <th>word_although</th>\n",
              "      <th>word_alway</th>\n",
              "      <th>word_amaz</th>\n",
              "      <th>word_ambianc</th>\n",
              "      <th>word_amor</th>\n",
              "      <th>word_andmor</th>\n",
              "      <th>word_ani</th>\n",
              "      <th>word_antoni</th>\n",
              "      <th>word_anyon</th>\n",
              "      <th>word_appet</th>\n",
              "      <th>word_area</th>\n",
              "      <th>word_aremor</th>\n",
              "      <th>word_around</th>\n",
              "      <th>word_ask</th>\n",
              "      <th>word_ate</th>\n",
              "      <th>word_atmospher</th>\n",
              "      <th>word_attent</th>\n",
              "      <th>word_authent</th>\n",
              "      <th>word_avail</th>\n",
              "      <th>word_averag</th>\n",
              "      <th>word_away</th>\n",
              "      <th>...</th>\n",
              "      <th>word_total</th>\n",
              "      <th>word_town</th>\n",
              "      <th>word_tradit</th>\n",
              "      <th>word_treat</th>\n",
              "      <th>word_tri</th>\n",
              "      <th>word_trikala</th>\n",
              "      <th>word_trip</th>\n",
              "      <th>word_truffl</th>\n",
              "      <th>word_two</th>\n",
              "      <th>word_typic</th>\n",
              "      <th>word_uniqu</th>\n",
              "      <th>word_us</th>\n",
              "      <th>word_use</th>\n",
              "      <th>word_usmor</th>\n",
              "      <th>word_valu</th>\n",
              "      <th>word_varieti</th>\n",
              "      <th>word_vegetarian</th>\n",
              "      <th>word_veri</th>\n",
              "      <th>word_view</th>\n",
              "      <th>word_villag</th>\n",
              "      <th>word_visit</th>\n",
              "      <th>word_wa</th>\n",
              "      <th>word_wait</th>\n",
              "      <th>word_waiter</th>\n",
              "      <th>word_waitress</th>\n",
              "      <th>word_want</th>\n",
              "      <th>word_warm</th>\n",
              "      <th>word_way</th>\n",
              "      <th>word_week</th>\n",
              "      <th>word_welcom</th>\n",
              "      <th>word_well</th>\n",
              "      <th>word_went</th>\n",
              "      <th>word_wide</th>\n",
              "      <th>word_wine</th>\n",
              "      <th>word_withoutmor</th>\n",
              "      <th>word_wonder</th>\n",
              "      <th>word_work</th>\n",
              "      <th>word_worth</th>\n",
              "      <th>word_would</th>\n",
              "      <th>word_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>visit thi place friend wa veri nice restaur sp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.8271</td>\n",
              "      <td>76</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278273</td>\n",
              "      <td>0.182338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deserv everi star given trip advisor delici pl...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>122</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.316964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>great good valu money must visit larissa also ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.7906</td>\n",
              "      <td>95</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.381111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.243075</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>went friend took seat garden nice set comfort ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.306</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>179</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>beauti cosi place delici big portion congratul...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>73</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 403 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9c8f31f-a46b-4370-a1c8-21f9c12204e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9c8f31f-a46b-4370-a1c8-21f9c12204e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9c8f31f-a46b-4370-a1c8-21f9c12204e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              Review  ... word_year\n",
              "0  visit thi place friend wa veri nice restaur sp...  ...       0.0\n",
              "1  deserv everi star given trip advisor delici pl...  ...       0.0\n",
              "2  great good valu money must visit larissa also ...  ...       0.0\n",
              "3  went friend took seat garden nice set comfort ...  ...       0.0\n",
              "4  beauti cosi place delici big portion congratul...  ...       0.0\n",
              "\n",
              "[5 rows x 403 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4f98fae6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f98fae6",
        "outputId": "316b2410-508b-4afb-cdd7-6c9da6e7ecb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1040, 403)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9022e9f5",
      "metadata": {
        "id": "9022e9f5"
      },
      "outputs": [],
      "source": [
        "df.Rating = df.Rating.replace({\"positive\":1,\"negative\":0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ba1528f5",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "ba1528f5",
        "outputId": "fa3b9aec-75e2-43c3-f0ad-cdbe9d375cb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30851486-c8a1-43a3-9367-03d346b9d3b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>nb_chars</th>\n",
              "      <th>nb_words</th>\n",
              "      <th>word_10</th>\n",
              "      <th>word_20</th>\n",
              "      <th>word_abov</th>\n",
              "      <th>word_absolut</th>\n",
              "      <th>word_advisor</th>\n",
              "      <th>word_afford</th>\n",
              "      <th>word_ago</th>\n",
              "      <th>word_akamatra</th>\n",
              "      <th>word_almost</th>\n",
              "      <th>word_along</th>\n",
              "      <th>word_also</th>\n",
              "      <th>word_although</th>\n",
              "      <th>word_alway</th>\n",
              "      <th>word_amaz</th>\n",
              "      <th>word_ambianc</th>\n",
              "      <th>word_amor</th>\n",
              "      <th>word_andmor</th>\n",
              "      <th>word_ani</th>\n",
              "      <th>word_antoni</th>\n",
              "      <th>word_anyon</th>\n",
              "      <th>word_appet</th>\n",
              "      <th>word_area</th>\n",
              "      <th>word_aremor</th>\n",
              "      <th>word_around</th>\n",
              "      <th>word_ask</th>\n",
              "      <th>word_ate</th>\n",
              "      <th>word_atmospher</th>\n",
              "      <th>word_attent</th>\n",
              "      <th>word_authent</th>\n",
              "      <th>word_avail</th>\n",
              "      <th>word_averag</th>\n",
              "      <th>word_away</th>\n",
              "      <th>...</th>\n",
              "      <th>word_total</th>\n",
              "      <th>word_town</th>\n",
              "      <th>word_tradit</th>\n",
              "      <th>word_treat</th>\n",
              "      <th>word_tri</th>\n",
              "      <th>word_trikala</th>\n",
              "      <th>word_trip</th>\n",
              "      <th>word_truffl</th>\n",
              "      <th>word_two</th>\n",
              "      <th>word_typic</th>\n",
              "      <th>word_uniqu</th>\n",
              "      <th>word_us</th>\n",
              "      <th>word_use</th>\n",
              "      <th>word_usmor</th>\n",
              "      <th>word_valu</th>\n",
              "      <th>word_varieti</th>\n",
              "      <th>word_vegetarian</th>\n",
              "      <th>word_veri</th>\n",
              "      <th>word_view</th>\n",
              "      <th>word_villag</th>\n",
              "      <th>word_visit</th>\n",
              "      <th>word_wa</th>\n",
              "      <th>word_wait</th>\n",
              "      <th>word_waiter</th>\n",
              "      <th>word_waitress</th>\n",
              "      <th>word_want</th>\n",
              "      <th>word_warm</th>\n",
              "      <th>word_way</th>\n",
              "      <th>word_week</th>\n",
              "      <th>word_welcom</th>\n",
              "      <th>word_well</th>\n",
              "      <th>word_went</th>\n",
              "      <th>word_wide</th>\n",
              "      <th>word_wine</th>\n",
              "      <th>word_withoutmor</th>\n",
              "      <th>word_wonder</th>\n",
              "      <th>word_work</th>\n",
              "      <th>word_worth</th>\n",
              "      <th>word_would</th>\n",
              "      <th>word_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>visit thi place friend wa veri nice restaur sp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.8271</td>\n",
              "      <td>76</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278273</td>\n",
              "      <td>0.182338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deserv everi star given trip advisor delici pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>122</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.316964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>great good valu money must visit larissa also ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.7906</td>\n",
              "      <td>95</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.381111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.243075</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>went friend took seat garden nice set comfort ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.306</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>179</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>beauti cosi place delici big portion congratul...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>73</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 403 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30851486-c8a1-43a3-9367-03d346b9d3b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30851486-c8a1-43a3-9367-03d346b9d3b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30851486-c8a1-43a3-9367-03d346b9d3b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              Review  ...  word_year\n",
              "0  visit thi place friend wa veri nice restaur sp...  ...        0.0\n",
              "1  deserv everi star given trip advisor delici pl...  ...        0.0\n",
              "2  great good valu money must visit larissa also ...  ...        0.0\n",
              "3  went friend took seat garden nice set comfort ...  ...        0.0\n",
              "4  beauti cosi place delici big portion congratul...  ...        0.0\n",
              "\n",
              "[5 rows x 403 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "88ee4c85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "88ee4c85",
        "outputId": "7a09deb3-3a27-43b5-8fc2-2015ca8cb421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4187683-6d20-4769-9be8-de952d742d35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_10</th>\n",
              "      <th>word_20</th>\n",
              "      <th>word_abov</th>\n",
              "      <th>word_absolut</th>\n",
              "      <th>word_advisor</th>\n",
              "      <th>word_afford</th>\n",
              "      <th>word_ago</th>\n",
              "      <th>word_akamatra</th>\n",
              "      <th>word_almost</th>\n",
              "      <th>word_along</th>\n",
              "      <th>word_also</th>\n",
              "      <th>word_although</th>\n",
              "      <th>word_alway</th>\n",
              "      <th>word_amaz</th>\n",
              "      <th>word_ambianc</th>\n",
              "      <th>word_amor</th>\n",
              "      <th>word_andmor</th>\n",
              "      <th>word_ani</th>\n",
              "      <th>word_antoni</th>\n",
              "      <th>word_anyon</th>\n",
              "      <th>word_appet</th>\n",
              "      <th>word_area</th>\n",
              "      <th>word_aremor</th>\n",
              "      <th>word_around</th>\n",
              "      <th>word_ask</th>\n",
              "      <th>word_ate</th>\n",
              "      <th>word_atmospher</th>\n",
              "      <th>word_attent</th>\n",
              "      <th>word_authent</th>\n",
              "      <th>word_avail</th>\n",
              "      <th>word_averag</th>\n",
              "      <th>word_away</th>\n",
              "      <th>word_awesom</th>\n",
              "      <th>word_back</th>\n",
              "      <th>word_bar</th>\n",
              "      <th>word_beauti</th>\n",
              "      <th>word_becaus</th>\n",
              "      <th>word_beer</th>\n",
              "      <th>word_befor</th>\n",
              "      <th>word_best</th>\n",
              "      <th>...</th>\n",
              "      <th>word_total</th>\n",
              "      <th>word_town</th>\n",
              "      <th>word_tradit</th>\n",
              "      <th>word_treat</th>\n",
              "      <th>word_tri</th>\n",
              "      <th>word_trikala</th>\n",
              "      <th>word_trip</th>\n",
              "      <th>word_truffl</th>\n",
              "      <th>word_two</th>\n",
              "      <th>word_typic</th>\n",
              "      <th>word_uniqu</th>\n",
              "      <th>word_us</th>\n",
              "      <th>word_use</th>\n",
              "      <th>word_usmor</th>\n",
              "      <th>word_valu</th>\n",
              "      <th>word_varieti</th>\n",
              "      <th>word_vegetarian</th>\n",
              "      <th>word_veri</th>\n",
              "      <th>word_view</th>\n",
              "      <th>word_villag</th>\n",
              "      <th>word_visit</th>\n",
              "      <th>word_wa</th>\n",
              "      <th>word_wait</th>\n",
              "      <th>word_waiter</th>\n",
              "      <th>word_waitress</th>\n",
              "      <th>word_want</th>\n",
              "      <th>word_warm</th>\n",
              "      <th>word_way</th>\n",
              "      <th>word_week</th>\n",
              "      <th>word_welcom</th>\n",
              "      <th>word_well</th>\n",
              "      <th>word_went</th>\n",
              "      <th>word_wide</th>\n",
              "      <th>word_wine</th>\n",
              "      <th>word_withoutmor</th>\n",
              "      <th>word_wonder</th>\n",
              "      <th>word_work</th>\n",
              "      <th>word_worth</th>\n",
              "      <th>word_would</th>\n",
              "      <th>word_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.278273</td>\n",
              "      <td>0.182338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.381111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243075</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.278579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.267525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.207821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.306967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.340885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.261702</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.096524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.245022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.259551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.183781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1040 rows × 395 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4187683-6d20-4769-9be8-de952d742d35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4187683-6d20-4769-9be8-de952d742d35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4187683-6d20-4769-9be8-de952d742d35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      word_10   word_20  word_abov  ...  word_worth  word_would  word_year\n",
              "0         0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "1         0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "2         0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "3         0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "4         0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "...       ...       ...        ...  ...         ...         ...        ...\n",
              "1035      0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "1036      0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "1037      0.0  0.289915        0.0  ...         0.0         0.0        0.0\n",
              "1038      0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "1039      0.0  0.000000        0.0  ...         0.0         0.0        0.0\n",
              "\n",
              "[1040 rows x 395 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X = log_X = df.iloc[:, 8:]\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "453ae346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "453ae346",
        "outputId": "d4641d53-b9ef-4fbc-8c52-09fc07ed319b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1035    1\n",
              "1036    1\n",
              "1037    1\n",
              "1038    1\n",
              "1039    1\n",
              "Name: Rating, Length: 1040, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y = df.Rating\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
      ],
      "metadata": {
        "id": "-8UcwiAI4P62"
      },
      "id": "-8UcwiAI4P62",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6c59cde1",
      "metadata": {
        "id": "6c59cde1"
      },
      "source": [
        "# Apply the following ML algorithms to the vectorized dataset:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## i. LogisticRegression"
      ],
      "metadata": {
        "id": "HnO6pYiGqgd7"
      },
      "id": "HnO6pYiGqgd7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99bdef8",
      "metadata": {
        "id": "e99bdef8"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(penalty=\"l2\",C=0.1,solver='lbfgs')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_lr = cross_val_score(lr, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "metadata": {
        "id": "xlKS9gfW4ckM"
      },
      "id": "xlKS9gfW4ckM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_lr), np.std(scores_lr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3QrK2Vj4lbQ",
        "outputId": "e499572e-6607-4355-e6a7-409eaf8820fd"
      },
      "id": "l3QrK2Vj4lbQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.913 (0.018)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d215546",
      "metadata": {
        "id": "6d215546"
      },
      "source": [
        "## ii. KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a275bcb",
      "metadata": {
        "id": "4a275bcb"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8fded8",
      "metadata": {
        "id": "2c8fded8"
      },
      "outputs": [],
      "source": [
        "k_scores = []\n",
        "k_range = range(1, 21)\n",
        "\n",
        "for K in k_range:\n",
        "    model_knn = KNeighborsClassifier(n_neighbors = K, metric = 'minkowski', p = 2)\n",
        "\n",
        "    scores = cross_val_score(model_knn, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    k_scores.append(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot to see clearly\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "MUc1NRJM6LSm",
        "outputId": "293216ee-8ee4-4b1f-ef29-ffc0d89b01e4"
      },
      "id": "MUc1NRJM6LSm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2152b2",
      "metadata": {
        "id": "3e2152b2"
      },
      "source": [
        "From the accuracy we observe that the best value is at K=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a85175e",
      "metadata": {
        "id": "1a85175e"
      },
      "outputs": [],
      "source": [
        "model_knn = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6398c36",
      "metadata": {
        "id": "f6398c36"
      },
      "outputs": [],
      "source": [
        "scores_knn = cross_val_score(model_knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c85401",
      "metadata": {
        "id": "30c85401",
        "outputId": "a3563c25-c415-42f2-d60a-5fe8d15fa022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.951 (0.017)\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_knn), np.std(scores_knn)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb421e8b",
      "metadata": {
        "id": "cb421e8b"
      },
      "source": [
        "## iii. RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78f4547",
      "metadata": {
        "id": "b78f4547"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af59969f",
      "metadata": {
        "id": "af59969f"
      },
      "outputs": [],
      "source": [
        "k_scores = []\n",
        "k_range = [5,10,15,20,25,30,35,40]\n",
        "for K in k_range:\n",
        "    \n",
        "    model_rf = RandomForestClassifier(n_estimators=K)\n",
        "\n",
        "    scores = cross_val_score(model_rf, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    k_scores.append(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot to see clearly\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of estimators for Random Forest')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MpUm0Rdd7ctB",
        "outputId": "50362def-081b-421a-9e8e-6b987ecce66b"
      },
      "id": "MpUm0Rdd7ctB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc043be8",
      "metadata": {
        "id": "dc043be8"
      },
      "source": [
        "We observe that for k=15-20 estimators our accuracy is the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fbe4abb",
      "metadata": {
        "id": "8fbe4abb"
      },
      "outputs": [],
      "source": [
        "model_rf=RandomForestClassifier(n_estimators=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabb9400",
      "metadata": {
        "id": "eabb9400"
      },
      "outputs": [],
      "source": [
        "scores_rf = cross_val_score(model_rf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d42b81b",
      "metadata": {
        "id": "4d42b81b",
        "outputId": "f07e7750-51bc-48a9-821d-61a553f620f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.958 (0.023)\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_rf), np.std(scores_rf)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ccaadb7",
      "metadata": {
        "id": "7ccaadb7"
      },
      "source": [
        "## iv. GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cd8749",
      "metadata": {
        "id": "b4cd8749"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bd45ec",
      "metadata": {
        "id": "41bd45ec"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e05c07",
      "metadata": {
        "id": "25e05c07"
      },
      "outputs": [],
      "source": [
        "scores_nb = cross_val_score(nb, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002ffa5c",
      "metadata": {
        "id": "002ffa5c",
        "outputId": "bb929b87-d735-48c6-a9c5-1a30b1d16d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.892 (0.021)\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_nb), np.std(scores_nb)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c216d960",
      "metadata": {
        "id": "c216d960"
      },
      "source": [
        "## v. SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa98e96",
      "metadata": {
        "id": "6fa98e96"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd76bb71",
      "metadata": {
        "id": "fd76bb71"
      },
      "outputs": [],
      "source": [
        "model_svc = svm.SVC() # Rbf Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d76771",
      "metadata": {
        "id": "a1d76771"
      },
      "outputs": [],
      "source": [
        "scores_svc = cross_val_score(model_svc, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd8ef2f",
      "metadata": {
        "id": "1bd8ef2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c823b3dc-f16e-4ef5-c2bc-9ce1ba746027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.958 (0.023)\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_svc), np.std(scores_svc)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d2fa5a",
      "metadata": {
        "id": "76d2fa5a"
      },
      "source": [
        "## vi. Long Short-Term Memory (LSTM) – Keras Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253b1c8d",
      "metadata": {
        "id": "253b1c8d"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "batch_size = 32\n",
        "verbosity = 1\n",
        "no_epochs = 5\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "for train, test in cv.split(X.values, y.values):\n",
        "  X1 = X.values\n",
        "  y1 = y.values\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(728, 120, input_length = X.shape[1]))\n",
        "  model.add(SpatialDropout1D(0.4))\n",
        "  model.add(LSTM(176, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(1,activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "    # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X1[train], y1[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X1[test], y1[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EskxmbM0CrIn",
        "outputId": "ef6d884b-bb23-4035-a7c4-604736375a10"
      },
      "id": "EskxmbM0CrIn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_5 (Spatia  (None, 395, 120)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9145\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9145\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0000e+00 - accuracy: 0.9145\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0000e+00 - accuracy: 0.9145\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9145\n",
            "Score for fold 1: loss of 0.0; accuracy of 90.38461446762085%\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_6 (Spatia  (None, 395, 120)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Score for fold 2: loss of 0.0; accuracy of 91.34615659713745%\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_7 (Spatia  (None, 395, 120)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0000e+00 - accuracy: 0.9124\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9124\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9124\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9124\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9124\n",
            "Score for fold 3: loss of 0.0; accuracy of 92.30769276618958%\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_8 (Spatia  (None, 395, 120)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9167\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9167\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9167\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9167\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9167\n",
            "Score for fold 4: loss of 0.0; accuracy of 88.46153616905212%\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_9 (Spatia  (None, 395, 120)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Score for fold 5: loss of 0.0; accuracy of 89.42307829856873%\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_10 (Spati  (None, 395, 120)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Score for fold 6: loss of 0.0; accuracy of 93.2692289352417%\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_11 (Spati  (None, 395, 120)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9103\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9103\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9103\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9103\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9103\n",
            "Score for fold 7: loss of 0.0; accuracy of 94.2307710647583%\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_12 (Spati  (None, 395, 120)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9113\n",
            "Score for fold 8: loss of 0.0; accuracy of 93.2692289352417%\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_13 (Spati  (None, 395, 120)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9135\n",
            "Score for fold 9: loss of 0.0; accuracy of 91.34615659713745%\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 395, 120)          87360     \n",
            "                                                                 \n",
            " spatial_dropout1d_14 (Spati  (None, 395, 120)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 177       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,625\n",
            "Trainable params: 296,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0000e+00 - accuracy: 0.9156\n",
            "Score for fold 10: loss of 0.0; accuracy of 89.42307829856873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09943f78",
      "metadata": {
        "id": "09943f78"
      },
      "source": [
        "## vii. AutoSklearnClassifier (from autosklearn.classification import AutoSklearnClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "904bb468",
      "metadata": {
        "id": "904bb468"
      },
      "outputs": [],
      "source": [
        "from autosklearn.classification import AutoSklearnClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1ZtX6Ay8FSgC",
        "outputId": "db2fb719-219f-46d6-e3c2-1faff0ee695c"
      },
      "id": "1ZtX6Ay8FSgC",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.14.3.tar.gz (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.19.5)\n",
            "Collecting scipy>=1.7.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.0)\n",
            "Collecting scikit-learn<0.25.0,>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting dask>=2021.12\n",
            "  Downloading dask-2022.1.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 62.4 MB/s \n",
            "\u001b[?25hCollecting distributed>=2012.12\n",
            "  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.5)\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.0.0)\n",
            "Collecting ConfigSpace<0.5,>=0.4.14\n",
            "  Downloading ConfigSpace-0.4.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 41.2 MB/s \n",
            "\u001b[?25hCollecting pynisher>=0.6.3\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "Collecting pyrfr<0.9,>=0.8.1\n",
            "  Downloading pyrfr-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting smac>=0.14\n",
            "  Downloading smac-1.1.1-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (3.0.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.26)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (0.11.2)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (1.3.0)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (21.3)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.11.3)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.3)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.4.8)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Collecting emcee>=3.0.0\n",
            "  Downloading emcee-3.1.1-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2012.12->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2012.12->auto-sklearn) (2.0.1)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, liac-arff\n",
            "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.14.3-py3-none-any.whl size=6586730 sha256=4a4f386e38688ab3d708fb2d8b48f63aa83abb15e2f5804407c83bc27acf9a2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/df/95/a197368c9745885b878f69ae3d6aec0941ccc28e5e1ce585d4\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=b9c5d7f73e9d25db33df79c09613ae8c6c4df2845aef0ce19497e339bfa9f2ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/71/95/7555ec3253e1ba8add72ae5febf1b015d297f3b73ba296d6f6\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=06cba42f861b34d39aa2b629a62363d45dcc2ced47738099ef6cb0a5b338fe69\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built auto-sklearn pynisher liac-arff\n",
            "Installing collected packages: locket, pyyaml, partd, fsspec, cloudpickle, scipy, dask, scikit-learn, pyrfr, pynisher, emcee, distributed, ConfigSpace, smac, liac-arff, auto-sklearn\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.20 auto-sklearn-0.14.3 cloudpickle-2.0.0 dask-2022.1.0 distributed-2022.1.0 emcee-3.1.1 fsspec-2022.1.0 liac-arff-2.5.0 locket-0.2.1 partd-1.2.0 pynisher-0.6.4 pyrfr-0.8.2 pyyaml-6.0 scikit-learn-0.24.2 scipy-1.7.3 smac-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scipy==1.7.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCjDvAZ_FZfW",
        "outputId": "9b05e9c8-4b72-4614-9c67-1e536a8b425e"
      },
      "id": "sCjDvAZ_FZfW",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.3) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_auto = AutoSklearnClassifier()"
      ],
      "metadata": {
        "id": "iKgBxUxpoBHf"
      },
      "id": "iKgBxUxpoBHf",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_auto = cross_val_score(model_auto, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "metadata": {
        "id": "SQFLEm1zoBJu"
      },
      "id": "SQFLEm1zoBJu",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_auto), np.std(scores_auto)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wEXYZvmqJJO",
        "outputId": "3ef34ee3-96d9-4419-c95c-87c09f3737f9"
      },
      "id": "7wEXYZvmqJJO",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.957 (0.020)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ac6a66",
      "metadata": {
        "id": "24ac6a66"
      },
      "source": [
        "## viii. Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328c6823",
      "metadata": {
        "id": "328c6823"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c50eac",
      "metadata": {
        "id": "83c50eac"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(max_depth=6,n_estimators=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319827dc",
      "metadata": {
        "id": "319827dc"
      },
      "outputs": [],
      "source": [
        "scores_xgb = cross_val_score(xgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354bce4b",
      "metadata": {
        "id": "354bce4b",
        "outputId": "953ca679-9c93-45d6-a2e0-cfa533be11ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.958 (0.018)\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: %.3f (%.3f)' % (np.mean(scores_xgb), np.std(scores_xgb)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}